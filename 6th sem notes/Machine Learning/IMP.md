# Machine Learning Exam Questions - Priority by Frequency

## **HIGH PRIORITY (Asked 4-5 times)**

### 1. **Machine Learning Fundamentals & Concepts** (5 times)

- Define machine learning and differentiate from traditional programming
- Explain machine learning concept with examples
- Types of machine learning algorithms
- Key components and perspectives in machine learning
- **Priority: HIGHEST**

### 2. **Neural Networks & Deep Learning** (5 times)

- Types of neural networks
- Multilayer perceptron with diagrams
- Feed-forward vs recurrent networks
- Neural network layers (convolution, pooling, dense, loss layers)
- **Priority: HIGHEST**

### 3. **Convolutional Neural Networks (CNN)** (4 times)

- CNN architecture and operation
- How CNNs process input data through multiple layers
- Pooling layers and spatial dimension reduction
- CNN implementation and applications
- **Priority: VERY HIGH**

### 4. **Reinforcement Learning** (4 times)

- Define reinforcement learning and its framework
- Elements of reinforcement learning
- Applications and use cases
- RL vs other ML approaches
- **Priority: VERY HIGH**

## **MEDIUM-HIGH PRIORITY (Asked 3 times)**

### 5. **Backpropagation Algorithm** (3 times)

- Backpropagation process and algorithm
- Chain rule in backpropagation
- Weight updates using backpropagation
- **Priority: HIGH**

### 6. **Q-Learning** (3 times)

- Q-learning algorithm explanation
- Q-learning with deterministic rewards
- Q-learning implementation
- **Priority: HIGH**

### 7. **Support Vector Machine (SVM)** (3 times)

- SVM concept and detailed explanation
- Support vectors and decision boundary
- SVM applications
- **Priority: HIGH**

### 8. **Bayesian Learning & Networks** (3 times)

- Bayesian learning fundamentals
- Bayes' theorem with examples
- Bayesian networks and probability tables
- **Priority: HIGH**

## **MEDIUM PRIORITY (Asked 2 times)**

### 9. **Data Preprocessing & Normalization** (2 times)

- Role of data preprocessing
- Data normalization importance
- Data augmentation techniques

### 10. **Activation Functions** (2 times)

- Sigmoid activation function
- ReLU vs Sigmoid comparison
- Vanishing gradient problem

### 11. **Principal Component Analysis (PCA)** (2 times)

- PCA for dimensionality reduction
- PCA process and implementation

### 12. **Gradient Descent** (2 times)

- Gradient descent concept
- Types of gradient descent optimizers

### 13. **LSTM & RNN** (2 times)

- LSTM architecture and gates
- RNN types and architecture
- Sequential data processing

### 14. **Value Iteration vs Policy Iteration** (2 times)

- Difference between value and policy iteration
- Implementation in reinforcement learning

### 15. **Markov Decision Process (MDP)** (2 times)

- MDP concept and framework
- MDP in reinforcement learning context

### 16. **Transfer Learning** (2 times)

- Transfer learning benefits and types
- Feature extraction vs fine-tuning

### 17. **Computer Vision Applications** (2 times)

- ML in computer vision
- Computer vision examples and applications

### 18. **Natural Language Processing** (2 times)

- NLP concepts and applications
- NLP in machine learning context

## **LOW PRIORITY (Asked 1 time)**

### Single Occurrence Topics:

- Linear regression and hypothesis function
- Perceptron concept
- Classification vs regression
- Sub-sampling in neural networks
- Keras framework features
- Actor-critic model
- SARSA algorithm
- One-hot vs label encoding
- Inception network architecture
- Confusion metrics
- KNN implementation
- Hyperparameter tuning
- Regularization (L1/L2)
- Overfitting/underfitting
- BLEU score calculation
- Speech processing applications
- Convex optimization
- Batch normalization
- Attention models
- Locally weighted linear regression
- Model selection


## **Key Insight**

The most consistent themes across all papers are:

1. **Fundamental ML concepts** - Always tested
2. **Neural Networks & CNNs** - Core of modern ML
3. **Reinforcement Learning** - Increasingly important
4. **Classic algorithms** (SVM, Bayesian) - Foundational knowledge